### From Simple to Complex Scenes: Learning Robust Feature Representations for Accurate Human Parsing

#### 摘要

在本文中，我们的目标是探索几个有用的特性，包括高分辨率表示，辅助指导和模型鲁棒性，这些特性共同导致在简单和复杂场景中进行准确的人类解析的新方法。

从**简单场景**出发，提出了一种边界感知混合分辨率网络(BHRN)，该网络利用反卷积层和多尺度监督来生成丰富的高分辨率表示，同时引入边缘感知分支来增强部分边界的精细度。此外，我们构建了一个基于BHRN的双任务互学习(DTML)框架，该框架不仅通过结合边界特征为解析器提供隐式指导，而且还明确地保持了解析预测与边界像素周围的基础真值之间的高阶一致性。针对**复杂场景**，提出了一种域变换方法来增强模型的鲁棒性。通过将输入空间从空间域转换到极调和傅立叶矩域，到输出语义空间的映射关系是高度稳定的，对干净和损坏的数据都产生鲁棒的表示。

#### 简介

目前，大多数现有的方法主要集中在两个方面来提高人工解析的性能。

**High-resolution feature representations.**

在这项工作中，我们提出了一个混合分辨率网络(HyRNet)来聚合丰富的高分辨率表示。如图7e所示，我们从HRNet中获得灵感，提取不同分辨率的特征。

如图7f所示，我们修改了HRNet的聚合模块。我们的HyRNet-利用反卷积层来重建高分辨率表示;此外，我们的HyRNet增加了辅助监督，以在每个尺度上生成判别特征。由于反卷积和辅助监督都是高效的，我们的HyRNet能够生成丰富的高分辨率特征表示，从而允许准确的人工解析。

**Auxiliary tasks for human parsing.**

在这项工作中，我们提出了一种**边界感知混合分辨率网络(BHRN)**，该网络将我们的HyRNet与边缘感知分支(EPB)相结合。EPB的目的是使中间特征空间更集中于零件边界。我们提出了一种**双任务互学习(DTML)框架**，利用辅助指导逐步细化解析结果。此外，我们试图以一种明确的方式约束人类解析的预测。为了实现这一点，我们开发了一种**边缘引导区域互信息损失(EG-RMI)**。考虑到边界像素构成语义变化的敏感区域，我们的EG-RMI损失鼓励人类解析器更多地关注边界，从而允许解析预测与其基本事实之间的高阶一致性。通过适当地使用边缘检测作为辅助任务，我们的方法在最小的模型参数增加的情况下实现了性能的显著提高。

在本文中，我们提出了一种有效的域变换方法，从一个新的角度学习鲁棒表示，这有助于显着提高对损坏图像的性能。如图2所示，我们在训练和推理阶段将输入空间转换为极调和傅立叶矩(PHFM)[28]域。由于PHFM对各种图像损坏的鲁棒性，训练模型的输入空间和输出语义空间之间的映射关系保持一致，从而可以在简单和复杂的场景中进行准确的预测。

![image-20230903201924067](C:\Users\lxc\AppData\Roaming\Typora\typora-user-images\image-20230903201924067.png)