### 刘老师分享

#### 基于语义对比学习的低光照图像增强网络

##### 介绍

我们提出了一种有效的**语义对比学习范式**用于LLE（即`SCL-LLE`）。在现有的低光图像增强先验知识之上，它将图像增强任务转换为**多任务联合学习**。其中，LLE 被转换为对比学习、语义亮度一致性和特征保存的三个约束，**以确保曝光、纹理和颜色的一致性**。SCL-LLE 允许 LLE 模型从未配对的正（正常光）/负（过度曝光）中学习，并使其与场景语义交互以规范化图像增强网络。

•SCL-LLE去除了像素对应的配对训练数据，并提供了一种更灵活的方式:1)在不同的现实世界域中使用未配对的图像进行训练，2)使用未配对的负样本进行训练，使我们能够利用现成的开放数据来构建一个更广义和判别的LLE网络。

•低级和高级视觉任务(即LLE和语义分割)相互促进。引入了语义亮度一致性损失，保证了同一语义类别亮度的平滑自然恢复。增强后的图像在下游语义分割上具有更好的性能。

##### 动机

一方面，没有亮度和颜色缺陷的高质量阳性样品在实践中很难获得。它给图像对配准和逐像素校准带来了复杂的问题。另一方面，带有错误曝光的负样品很容易获得。这样子更加灵活和鲁棒。

此外，在语义范畴内存在自然亮度一致性。采用这种一致性可以帮助避免局部不均匀的暴露。



##### 方法

如图2所示，我们为低光图像增强设计了一种新的语义对比学习框架（称为SCL-LLE）:

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/vgev6PHxuZ0otuz0GkHB4pfUVVkBaOszdSu3H8xtZT30FYibibicWlibicKMMcFUXgP6rcdicszbomDSN2H1XqogTvWQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



`SCL-LLE` 包含**图像增强网络**、**语义分割网络**和**特征提取网络**。具体而言，给定输入 ，首先应用图像增强网络，然后将增强的结果输入到接下来的语义分割网络中。对于任务模块，我们利用了三种主流网络：低光图像增强网络采用类似`U-Net`的骨干结构，通过生成像素校正曲线来重新映射每个像素；我们在这里使用的语义分割网络是流行的`DeepLabv3+`；特征提取网络采用的是`VGG-16`。



注解：**语义交互**是指通过自然语言处理技术，让计算机能够理解人类语言并进行相应的交互。**高级语义**是指计算机能够理解并处理更加复杂的语言结构和含义。（理解）

**语义分割**：与普通的图像分类不同，语义分割不仅可以识别图像中的物体，还可以对它们进行精确的定位。（精确的分类）

**多任务联合学习**是一种机器学习方法，旨在同时训练一个模型来执行多个相关任务。在这种方法中，模型可以共享底层的特征表示，从而提高模型的泛化能力和效率

**场景语义**是指理解自然语言中所描述的场景或情境背景的能力。它涉及到识别并理解语言中的实体、事件、关系等要素，并将它们与已知的知识或背景上下文进行连接和推理，从而获得对整个场景的更深层次理解。

#### PE-YOLO

##### 介绍

作者的贡献可以总结如下：

- 作者构建了一个金字塔增强网络（PENet），用于增强不同的暗光图像。作者提出了详细处理模块（DPM）和低频增强滤波器（LEF）来增强图像组成部分。
- 通过将PENet与YOLOv3结合，作者提出了一个端到端训练的暗目标检测框架PE-YOLO，以适应暗光条件。在训练过程中，作者只使用正常的检测损失。

##### 本方法

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/5ooHoYt0tgkzibz85ul8CqmXj48GM9bVKSUMd3QWNxHvc8Lb1WjLsRGTyniar8f7qsUCKECFCnR7JfnMPs3iaWg9g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

假设图像I属于R<sup>h×w×3</sup>作为输入，作者使用高斯金字塔获取不同分辨率的子图像。

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/5ooHoYt0tgkzibz85ul8CqmXj48GM9bVKicf6libllX2t4UIib60qCnHbzVFFBNnic8rcibp4U1Rpz2ibSUZxqxKmDSSg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

其中, Down表示下采样, Gaussian表示高斯滤波器,高斯核的大小为5×5。在每个高斯金字塔操作后，图像的宽度和高度减半，这意味着分辨率是原始图像的1/4。显然，**高斯金字塔的下采样操作是不可逆的。为了在上采样后恢复原始的高分辨率图像，需要恢复丢失的信息**，这些丢失的信息构成了拉普拉斯金字塔的组件。拉普拉斯金字塔的定义如下：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/5ooHoYt0tgkzibz85ul8CqmXj48GM9bVK198lAmaw29X0PoOcco7eUCiakC41icDqF7oKWPlYicYlxq2x7wFPkwVdg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

其中, L<sub>i</sub>表示拉普拉斯金字塔的第i层, G<sub>i</sub>表示高斯金字塔的第i层, Up表示双线性上采样操作。**在重建图像时, 作者只需要执行公式 (2)的逆操作, 即可恢复高分辨率图像**。

###### 细节信息增强

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/5ooHoYt0tgkzibz85ul8CqmXj48GM9bVKtTPw6Q0WMibxUkibR8TxaNcyo8TJmh6d2PzfjypkrvpmK9Ssdht7w9OA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**上下文分支**

作者使用残差块来在获取远程依赖性之前和之后处理特征，并且残差学习允许丰富的低频信息通过跳过连接进行传递。第一个残差块将特征的通道从3变为32，第二个残差块将特征的通道从32变为3。

##### ![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/5ooHoYt0tgkzibz85ul8CqmXj48GM9bVK882v37oByjwJLiaTqPt7O8g0S1esCy2nTUCKtcuE7IcdyrJvLMeffGw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

其中 ˆx = σ(F2(x))·x，F 是带有 卷积核的卷积层, γ是Leaky ReLU激 活函数, σ是 Softmax函数。

**Edge branch**

Sobel算子是一种离散算子，它同时使用了高斯滤波和差分求导。它通过计算梯度近似来找到边缘。作者在水平和垂直方向上都使用Sobel算子来通过卷积滤波器重新提取边缘信息，并使用残差来增强信息的流动。该过程表示为：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/5ooHoYt0tgkzibz85ul8CqmXj48GM9bVKZXOrDb8DMr1FqN2g549hiaqBO0wn6vP9CiaZCkDZBTaxrMbDtI54jibkw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

###### 低频增强滤波器

![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/5ooHoYt0tgkzibz85ul8CqmXj48GM9bVKmQ6hQHevKYjJictAhU4k4QK6c9EclsguJQib2rhrPdfxmYyFx2apLaKw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

作者使用动态低通滤波器来捕捉低频信息, 并且使用平均池化进行特征滤波, 只允许低于截止频率的信息通 过。

不同语义的低频阈值是不同的。考虑到Inception的多尺度结构, 作者使用大小为 1×1, 2×2, 3 × 3, 6 × 6的自适应平均池化, 并在每个尺度末尾使用上采样来恢复特征的原始大小。

​                                 Filter(f<sub>i</sub>) = Up(β<sub>s</sub>(f<sub>i</sub>)) 
